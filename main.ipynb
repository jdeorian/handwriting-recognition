{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Handwriting Recognition project\n",
    "\n",
    "By: John DeOrian\n",
    "\n",
    "Date started: March 13, 2020\n",
    "\n",
    "Last modified: March 15, 2020\n",
    "\n",
    "This workbook is my record of trying out different ML approaches to the handwriting recognition problem on Kaggle. I'll start off with more simple approaches and lead to more complicated approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T04:11:54.046892Z",
     "start_time": "2020-03-16T04:11:50.374791Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T04:11:58.064100Z",
     "start_time": "2020-03-16T04:11:54.059773Z"
    }
   },
   "outputs": [],
   "source": [
    "dfTrain = pd.read_csv('train.csv')\n",
    "dfTest = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random guessing\n",
    "\n",
    "As a baseline, I will guess a random number from 0 to 9. Since I can't test the model directly, I will upload it to Kaggle and report the results. I expect to achieve a 10% accuracy since we'd expect a random guess from 0 to 9 to be right ~10% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T05:03:32.918154Z",
     "start_time": "2020-03-14T05:03:32.594025Z"
    }
   },
   "outputs": [],
   "source": [
    "myGuesses = tuple((np.random.randint(0,10) for x in range(len(dfTest))))\n",
    "myLabels = tuple((x+1 for x in range(len(dfTest))))\n",
    "resultsDf = pd.DataFrame(zip(myLabels,myGuesses),columns=['ImageId','Label'])\n",
    "resultsDf.to_csv('results1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first submission matches our expectations and we achieve a 10.214% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "Next, I will use logistic regression to make predictions. I expect this to perform poorly, but better than random guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T05:54:07.346363Z",
     "start_time": "2020-03-14T05:31:37.427091Z"
    }
   },
   "outputs": [],
   "source": [
    "y = dfTrain.iloc[:,0]\n",
    "X = dfTrain.iloc[:,1:]\n",
    "\n",
    "clf = LogisticRegression().fit(X,y)\n",
    "print(clf.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T05:54:08.642933Z",
     "start_time": "2020-03-14T05:54:08.148219Z"
    }
   },
   "outputs": [],
   "source": [
    "myGuesses = clf.predict(dfTest)\n",
    "myLabels = tuple((x+1 for x in range(len(dfTest))))\n",
    "resultsDf = pd.DataFrame(zip(myLabels,myGuesses),columns=['ImageId','Label'])\n",
    "resultsDf.to_csv('results2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model achieve >90% accuracy! That's much, much better than I expected. At the same time, I'm concerned that the model never converged even after 10,000 iterations. I don't know why it's not working - a quick Google search suggests the problem might be \"complete or quasi-complete separation in the data\". That's over my head for now, but I may return to it later. For now, I'll ignore it as if the model converged without issue.\n",
    "\n",
    "Since logistic regression performed so well, I'll continue experimenting with it a couple more times before moving on to another model.\n",
    "\n",
    "My next experiment is to see how regularization affects the model's performance. Since the basic logit model had a train performance of ~94% and a test performance of ~92%, I expect regularization to reduce the gap between train and test. I do not expect train performance, itself, to improve.\n",
    "\n",
    "I begin with L1 regularization (aka Lasso Regression) because the effect of Lasso is to shrink less important feature coefficients to zero. This is useful when we have a large number of feature, which we do in this case with 784. The challenge here is to select an appropriate value for lambda. I'm not sure how sklearn works, yet, so I'll just go with default values for now. I'm required to change the solver because the default solver doesn't work with L1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T06:06:52.777702Z",
     "start_time": "2020-03-14T06:04:50.756742Z"
    }
   },
   "outputs": [],
   "source": [
    "y = dfTrain.iloc[:,0]\n",
    "X = dfTrain.iloc[:,1:]\n",
    "\n",
    "clf = LogisticRegression(solver='liblinear',penalty='l1').fit(X,y)\n",
    "print(clf.score(X,y))\n",
    "\n",
    "myGuesses = clf.predict(dfTest)\n",
    "myLabels = tuple((x+1 for x in range(len(dfTest))))\n",
    "resultsDf = pd.DataFrame(zip(myLabels,myGuesses),columns=['ImageId','Label'])\n",
    "resultsDf.to_csv('results3.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T05:14:26.679056Z",
     "start_time": "2020-03-14T05:14:26.672073Z"
    }
   },
   "source": [
    "I'll also train a model using L2 regularization (Ridge Regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T06:29:58.227423Z",
     "start_time": "2020-03-14T06:07:26.929005Z"
    }
   },
   "outputs": [],
   "source": [
    "y = dfTrain.iloc[:,0]\n",
    "X = dfTrain.iloc[:,1:]\n",
    "\n",
    "clf = LogisticRegression(penalty='l2').fit(X,y)\n",
    "print(clf.score(X,y))\n",
    "\n",
    "myGuesses = clf.predict(dfTest)\n",
    "myLabels = tuple((x+1 for x in range(len(dfTest))))\n",
    "resultsDf = pd.DataFrame(zip(myLabels,myGuesses),columns=['ImageId','Label'])\n",
    "resultsDf.to_csv('results4.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, Logistic regression had solid performance but some critical failures. First, the models won't converge. Even though they ended with >90% accuracy, I am unwilling to use a model that won't converge. Second, the models never performed better than 92%, so we'll have to look elsewhere to get additional accuracy gains. Finally, I want to note that I wasted a lot of time during training by increasing max_iter to 10,000. I did that to try and overcome the convergence problem, but it didn't helped and just cost time.\n",
    "\n",
    "At this point, I'm going to try another approach and see how it performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors\n",
    "\n",
    "I actually expect KNN to perform pretty well and definitely better than Logistic Regression. Since the pixel values for the same number will be similar, my intuition is that KNN will pick up similar values.\n",
    "\n",
    "It may be that, after performing basic KNN, I do some feature reduction and then redo KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T04:12:07.141755Z",
     "start_time": "2020-03-16T04:12:07.137740Z"
    }
   },
   "outputs": [],
   "source": [
    "y = dfTrain.iloc[:,0]\n",
    "X = dfTrain.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-15T22:44:41.922977Z",
     "start_time": "2020-03-15T22:23:54.844428Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors = 5).fit(X=X,y=y)\n",
    "myGuesses = clf.predict(dfTest)\n",
    "myLabels = tuple((x+1 for x in range(len(dfTest))))\n",
    "resultsDf = pd.DataFrame(zip(myLabels,myGuesses),columns=['ImageId','Label'])\n",
    "resultsDf.to_csv('results5.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic KNN scored 96.8% accuracy! That's pretty good and definitely better than Logistic Regression. The only downside is that it's painfully slow. \n",
    "\n",
    "Now I will experiment with different values for k to see whether it affects my score. I expect this to take a long time and not have a big effect. I'm just doing it for completeness sake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T04:12:11.900923Z",
     "start_time": "2020-03-16T04:12:11.712436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XTrain: (29400, 784), XTest: (12600, 784), yTrain:(29400,), and yTest:(12600,)\n"
     ]
    }
   ],
   "source": [
    "XTrain, XTest, yTrain, yTest = train_test_split(X, y, test_size=0.3)\n",
    "print('XTrain: {0}, XTest: {1}, yTrain:{2}, and yTest:{3}'.format(XTrain.shape,XTest.shape,yTrain.shape,yTest.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T01:23:11.763379Z",
     "start_time": "2020-03-15T23:52:51.177914Z"
    }
   },
   "outputs": [],
   "source": [
    "kRange = range(1,11)\n",
    "scores = {}\n",
    "\n",
    "for k in kRange:\n",
    "    clf = KNeighborsClassifier(n_neighbors=k).fit(X=XTrain, y=yTrain)\n",
    "    scores[k] = clf.score(X=XTest, y=yTest)\n",
    "    \n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, changing k did not have a meaningful effect on my outcomes. Also, it took a really long time (~1.5 hours!). One of the confusing things for me is why KNN works for this task when KNN is said to suffer from the curse of dimensionality. After some digging, I found a Quora post that talks about the blessing of non-uniformity. This basically says that curse of dimensionality is mostly an issue with random or uniformly distributed data. 'Real' data is not random or uniformly distributed, so the algorithm's accuracy is saved. This is a big, complex topic that I'll need to learn more about.\n",
    "\n",
    "Now, I'm going to rerun KNN but using Manhattan instead of Euclidean distance. Per some of my readings, it sounds like Manhattan might perform better with higher dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T04:38:00.497711Z",
     "start_time": "2020-03-16T04:17:59.191358Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(p=1).fit(X=X,y=y)\n",
    "myGuesses = clf.predict(dfTest)\n",
    "myLabels = tuple((x+1 for x in range(len(dfTest))))\n",
    "resultsDf = pd.DataFrame(zip(myLabels,myGuesses),columns=['ImageId','Label'])\n",
    "resultsDf.to_csv('results2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN with Manhattan distance performed the same as KNN with Euclidean - ~96%. Time to move onto another approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest\n",
    "tbd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
